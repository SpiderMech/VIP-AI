{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27985dfa",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a423dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fce7fa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id26305</td>\n",
       "      <td>This process, however, afforded me no means of...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id17569</td>\n",
       "      <td>It never once occurred to me that the fumbling...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id11008</td>\n",
       "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
       "      <td>EAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id27763</td>\n",
       "      <td>How lovely is spring As we looked from Windsor...</td>\n",
       "      <td>MWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id12958</td>\n",
       "      <td>Finding nothing else, not even gold, the Super...</td>\n",
       "      <td>HPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text author\n",
       "0  id26305  This process, however, afforded me no means of...    EAP\n",
       "1  id17569  It never once occurred to me that the fumbling...    HPL\n",
       "2  id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
       "3  id27763  How lovely is spring As we looked from Windsor...    MWS\n",
       "4  id12958  Finding nothing else, not even gold, the Super...    HPL"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('./data/train.csv')\n",
    "test_df = pd.read_csv('./data/test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91dc216c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    7900\n",
       "MWS    6044\n",
       "HPL    5635\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['author'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e923dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAP    0.403494\n",
       "MWS    0.308698\n",
       "HPL    0.287808\n",
       "Name: author, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['author'].value_counts() / len(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29ea4f",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "Credit: https://www.kaggle.com/code/sandpiturtle/eda-fe-nb-xgb/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4d588aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842b914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64188578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function used to replace named entities with ent__ORG\n",
    "def replace_ents(doc):\n",
    "    prefix = 'ent__'\n",
    "    text = str(doc.doc)\n",
    "    for ent in doc.ents:\n",
    "        text = text.replace(ent.orth_, prefix + ent.label_)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c82cc47",
   "metadata": {},
   "source": [
    "Define func to preprocess text data. Here I am doing the following:\n",
    "\n",
    "- Parsing text with spaCy\n",
    "- Handcrafting new features identifying number of:\n",
    "    - characters\n",
    "    - words\n",
    "    - punctuation characters\n",
    "    - named entities\n",
    "    - noun chunks\n",
    "    - unique words\n",
    "    - stop words\n",
    "    - characters by word\n",
    "- Replace named entities with tags like 'ent_ORG'\n",
    "- Lemmatize\n",
    "- Delete stopwords\n",
    "- Calculating a general sentiment score\n",
    "\n",
    "I leave 3 different versions (untouched, cleaned, entities replaced) of text in order to try which fits best with CV.\n",
    "\n",
    "British-American-ness only has 32 training examples where their values were greater than 0, so this was ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae74c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    print('Started parsing...')\n",
    "    doc = df.text.apply(nlp)\n",
    "    print('Text parsed')\n",
    "    \n",
    "    df['n_char']   = df.text.apply(len)\n",
    "    df['n_words']  = doc.apply(lambda x: len([t for t in x if not t.is_punct]))\n",
    "    df['n_punct']  = doc.apply(lambda x: len([t for t in x if t.is_punct]))\n",
    "    df['n_ents']   = doc.apply(lambda x: len(x.ents))\n",
    "    df['n_chunks'] = doc.apply(lambda x: len(list(x.noun_chunks)))\n",
    "    df['n_unique_words'] = doc.apply(lambda x: len(set([t.lower_ for t in x if not t.is_punct])))\n",
    "    df['n_stop_words']   = doc.apply(lambda x: len([t for t in x if t.is_stop]))\n",
    "    df['char_by_word']   = doc.apply(lambda x: np.mean([len(t.orth_) for t in x if not t.is_punct]))    \n",
    "    print('Features created')\n",
    "    \n",
    "    df['text_ent_repl'] = doc.apply(replace_ents)\n",
    "    print('Entities replaced')\n",
    "    \n",
    "    clean_and_lemmatize = lambda x: ' '.join([t.lemma_ for t in x if not t.is_punct and not t.is_stop])\n",
    "    df['text_cleaned'] = doc.apply(clean_and_lemmatize)\n",
    "    print('Text cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a353fe62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing...\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preprocess(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52216dc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "preprocess(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8ef5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from pywsd import disambiguate\n",
    "# nltk.download('sentiwordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9933e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sentiments = []\n",
    "docs = nlp.pipe(train_df['text'], disable=['ner'])\n",
    "\n",
    "for doc in docs:\n",
    "    sentiment = 0\n",
    "    for sentence in doc.sents:\n",
    "        for word, sysnet in disambiguate(sentence.text):\n",
    "            if sysnet is not None:\n",
    "                sysnet_senti = swn.senti_synset(sysnet.name())\n",
    "                sentiment += sysnet_senti.pos_score()\n",
    "                sentiment -= sysnet_senti.neg_score()\n",
    "    sentiments.append(sentiment)\n",
    "train_df['sentiment'] = pd.Series(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import re\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "\n",
    "class CurrentWordsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        self.words = {word: 1 for word in nlp.vocab.strings}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        count = []\n",
    "\n",
    "        for sentence in X:\n",
    "            current_count = 0\n",
    "            words = word_tokenize(re.sub('[%s]' % re.escape(string.punctuation), '', sentence.lower()))\n",
    "\n",
    "            for word in words:\n",
    "                if self.words.get(word, 0) == 1:\n",
    "                    current_count += 1/len(words)\n",
    "\n",
    "            count.append(current_count)\n",
    "\n",
    "        return pd.DataFrame(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b907d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_words = CurrentWordsTransformer()\n",
    "current_words_features = current_words.fit_transform(train_df['text'])\n",
    "train_df['how_current'] = current_words_features.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa702c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02edd8a9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Credit: https://www.kaggle.com/code/sandpiturtle/eda-fe-nb-xgb/notebook\n",
    "\n",
    "Note: Sample size is likely not large enough to truly represent the characteristics of our authors' writings. I.e., below we might find in this dataset that MWS generally write longer sentences than the rest of the authors, always think: is that true in the real world? Or in other words if we were able to collect everything all three authors have ever written and do the same comparison, will we still observe the same phenomenon of MWS writing longer sentences? If eventually we decide to use sentence length as a feature, this will affect our model's ability to predict with real world data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4efbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96d984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eap = train_df[train_df['author'] == 'EAP']\n",
    "mws = train_df[train_df['author'] == 'MWS']\n",
    "hpl = train_df[train_df['author'] == 'HPL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586b2c29",
   "metadata": {},
   "source": [
    "### Sentence Length\n",
    "Is there a difference in sentence length amongst the authors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f87430",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5215d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_outliers(s):\n",
    "    med = s.mean()\n",
    "    std = s.std()\n",
    "    return s[(med - 3*std <= s) & (s <= med + 3*std)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a8f3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7,4))\n",
    "sns.kdeplot(drop_outliers(eap.n_char), shade=True, color=\"r\");\n",
    "sns.kdeplot(drop_outliers(hpl.n_char), shade=True, color=\"g\");\n",
    "sns.kdeplot(drop_outliers(mws.n_char), shade=True, color=\"b\");\n",
    "ax.legend(labels=['EAP', 'HPL', 'MWS']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7ddbc",
   "metadata": {},
   "source": [
    "HPL sentences seem a bit longer than the rest, EAP's a bit shorter. This feature might be useful in helping us distinguish the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d31707",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a85b340",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7,4))\n",
    "sns.kdeplot(drop_outliers(eap.n_punct), shade=True, color=\"r\");\n",
    "sns.kdeplot(drop_outliers(hpl.n_punct), shade=True, color=\"g\");\n",
    "sns.kdeplot(drop_outliers(mws.n_punct), shade=True, color=\"b\");\n",
    "ax.legend(labels=['EAP', 'HPL', 'MWS']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4f82d3",
   "metadata": {},
   "source": [
    "Here HPL's punctuation distribution is different from others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4b8d2",
   "metadata": {},
   "source": [
    "### Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4edf76a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7,4))\n",
    "sns.kdeplot(drop_outliers(eap.sentiment), shade=True, color=\"r\");\n",
    "sns.kdeplot(drop_outliers(hpl.sentiment), shade=True, color=\"g\");\n",
    "sns.kdeplot(drop_outliers(mws.sentiment), shade=True, color=\"b\");\n",
    "ax.legend(labels=['EAP', 'HPL', 'MWS']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc9e1f8",
   "metadata": {},
   "source": [
    "Sentiment distribution seem to be similar for all authors, with EAP slightly more neutral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3515af9",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639ad9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ecccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_df['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5de810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_loss(model, train, test):\n",
    "    scores = cross_val_score(model, train, test, cv=10, n_jobs=-1, scoring='neg_log_loss')\n",
    "    print('LogLoss: %.3f +- %.3f' % (-np.mean(scores), 2*np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6868d",
   "metadata": {},
   "source": [
    "### Count Vectorised"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49462cba",
   "metadata": {},
   "source": [
    "#### Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe97db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(train_df.text_cleaned)\n",
    "get_log_loss(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0050a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_log_loss(LogisticRegression(max_iter=1000), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc73267",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_loss(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d95b760",
   "metadata": {},
   "source": [
    "#### Text with Entities Replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(1, 2))\n",
    "X = cv.fit_transform(train_df.text_ent_repl)\n",
    "get_log_loss(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294ea5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_log_loss(LogisticRegression(max_iter=1000), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddda8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_loss(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e915f",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74856a3",
   "metadata": {},
   "source": [
    "#### Cleaned Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03592287",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(ngram_range=(1,1), sublinear_tf=True)\n",
    "X = tfidf_v.fit_transform(train_df.text_cleaned)\n",
    "get_log_loss(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec840d15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_log_loss(LogisticRegression(max_iter=1000), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7b8f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_loss(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e0ca6",
   "metadata": {},
   "source": [
    "#### Text with Entities Replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53120a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = TfidfVectorizer(ngram_range=(1,1), sublinear_tf=True)\n",
    "X = tfidf_v.fit_transform(train_df.text_ent_repl)\n",
    "get_log_loss(MultinomialNB(), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889c2e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_log_loss(LogisticRegression(max_iter=1000), X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f800a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_log_loss(RandomForestClassifier(), X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c45c5d",
   "metadata": {},
   "source": [
    "### Meta Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dcbb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a65b5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = train_df.drop(['id', 'text', 'text_cleaned', 'text_ent_repl', 'author'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4875e",
   "metadata": {},
   "source": [
    "#### LGBM\n",
    "Light Gradient Boosting Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5784042",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbc = lgb.LGBMClassifier(objective='multiclass', n_estimators=100)\n",
    "get_log_loss(lgbc, X_meta, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fde03e",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8718d053",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_encoding = {\n",
    "    'EAP': 0,\n",
    "    'MWS': 1,\n",
    "    'HPL': 2\n",
    "}\n",
    "\n",
    "y_encoded = [author_encoding[auth] for auth in y]\n",
    "\n",
    "xgbc = xgb.XGBClassifier(objective='multi:softprob', n_estimators=200)\n",
    "get_log_loss(xgbc, X_meta, y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d3125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgbc.fit(X_meta, y_encoded)\n",
    "xgb.plot_importance(xgbc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8833c631",
   "metadata": {},
   "source": [
    "### Stacking Features\n",
    "We select the most important features and use our base model (NB) to make classifications. We then use these classifications as features for our LGBM and XGBoost classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f001147",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56379096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prob_features(vectorizer, col, model, prefix, cv=5):\n",
    "    vectorizer.fit(pd.concat([train_df[col], test_df[col]]))\n",
    "    X = vectorizer.transform(train_df[col])\n",
    "    X_test = vectorizer.transform(test_df[col])\n",
    "    \n",
    "    cv_scores = []\n",
    "    pred_test = 0\n",
    "    pred_train = np.zeros([train_df.shape[0], 3])\n",
    "    kf = StratifiedKFold(n_splits=cv, shuffle=True, random_state=123)\n",
    "    \n",
    "    print('CV started')\n",
    "    for train_index, dev_index in kf.split(X, y):\n",
    "        X_train, X_dev = X[train_index], X[dev_index]\n",
    "        y_train, y_dev = y[train_index], y[dev_index]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        pred_dev   = model.predict_proba(X_dev)\n",
    "        pred_test += model.predict_proba(X_test)\n",
    "    \n",
    "        pred_train[dev_index, :] = pred_dev\n",
    "        cv_scores.append(metrics.log_loss(y_dev, pred_dev))\n",
    "        print('.', end='')\n",
    "        \n",
    "    print('')\n",
    "    print(\"Mean CV LogLoss: %.3f\" % (np.mean(cv_scores)))\n",
    "    pred_test /= cv\n",
    "\n",
    "    train_df[prefix+'eap'] = pred_train[:, 0]\n",
    "    train_df[prefix+'hpl'] = pred_train[:, 1]\n",
    "    train_df[prefix+'mws'] = pred_train[:, 2]\n",
    "    \n",
    "    test_df[prefix+'eap'] = pred_test[:, 0]\n",
    "    test_df[prefix+'hpl'] = pred_test[:, 1]\n",
    "    test_df[prefix+'mws'] = pred_test[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5301fcec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2), stop_words='english'\n",
    ")\n",
    "add_prob_features(vectorizer, 'text', MultinomialNB(), 'nb_ctv_', cv=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    token_pattern=r'\\w{1,}', ngram_range=(1, 1), \n",
    "    use_idf=True, smooth_idf=True, sublinear_tf=True,\n",
    ")\n",
    "add_prob_features(vectorizer, 'text_cleaned', MultinomialNB(), 'nb_tfv_', cv=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa82f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 5), analyzer='char'\n",
    ")\n",
    "add_prob_features(vectorizer, 'text', MultinomialNB(), 'nb_char_', cv=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    ngram_range=(1, 2), stop_words='english'\n",
    ")\n",
    "add_prob_features(vectorizer, 'text_ent_repl', MultinomialNB(), 'nb_ent_', cv=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd801a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(['id', 'text', 'text_cleaned', 'text_ent_repl', 'author'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668488da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgbc = lgb.LGBMClassifier(objective='multiclass', n_estimators=150, num_leaves=10)\n",
    "scores = cross_val_score(lgbc, X, y, cv=4, n_jobs=1, scoring='neg_log_loss')\n",
    "print('LogLoss: %.3f +- %.3f' % (-np.mean(scores), 2*np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2487a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc = xgb.XGBClassifier(objective='multi:softprob', n_estimators=150)\n",
    "scores = cross_val_score(xgbc, X, y, cv=4, n_jobs=1, scoring='neg_log_loss')\n",
    "print('LogLoss: %.3f +- %.3f' % (-np.mean(scores), 2*np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f364d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
